{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses a vanilla (basic) Bayesian optimization algorithm to tackle an urban travel demand (i.e., origin-destination, OD) calibration problem. The traffic simulations are based on the SUMO simulator.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUMO configuration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mount GDrive**\n",
    "\n",
    "If you are working w/ colab rather than a jupyterlab notebook this drive mounting and sumo installation will need to be done every time you restart the runtime.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup venv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %python -m venv .venv\n",
    "# %source .venv/bin/activate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Install SUMO**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %sudo add-apt-repository -y ppa:sumo/stable\n",
    "# %sudo apt-get update\n",
    "# %sudo apt-get -y install sumo sumo-tools sumo-doc &"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set sumo env vars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environment variable\n",
    "import os\n",
    "import sys\n",
    "os.environ['SUMO_HOME'] = '/usr/share/sumo'\n",
    "os.environ['LIBSUMO_AS_TRACI'] = '1' #Optional: for a huge performance boost (~8x) with Libsumo (No GUI)\n",
    "\n",
    "if \"SUMO_HOME\" in os.environ:\n",
    "    tools = os.path.join(os.environ[\"SUMO_HOME\"], \"tools\")\n",
    "    sys.path.append(tools)\n",
    "else:\n",
    "    sys.exit(\"Please declare the environment variable 'SUMO_HOME'\")\n",
    "#import traci\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Macros / utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/app\"\n",
    "\n",
    "# if base_path has a space in it, the sumo code will not work\n",
    "if ' ' in base_path:\n",
    "    raise ValueError(\"base_path should not contain spaces\")\n",
    "\n",
    "os.chdir(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install missing packages\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch.quasirandom import SobolEngine\n",
    "\n",
    "from botorch import fit_gpytorch_mll\n",
    "from botorch.acquisition import qLogExpectedImprovement\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.models.transforms import Standardize\n",
    "from botorch.optim import optimize_acqf\n",
    "from botorch.sampling.stochastic_samplers import StochasticSampler\n",
    "from botorch.utils.transforms import unnormalize, normalize\n",
    "\n",
    "from gpytorch.constraints import Interval\n",
    "from gpytorch.kernels import MaternKernel, ScaleKernel\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "\n",
    "\n",
    "from bayesian_optimization.helpers import (load_kwargs_config, \n",
    "                    compute_nrmse_counts_all_edges, \n",
    "                    parse_loop_data_xml_to_pandas, \n",
    "                    create_taz_xml,\n",
    "                    simulate_od,\n",
    "                    od_xml_to_df,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_kwargs_config(base_path, \"bo_vanilla\", \"sim_setup.json\")\n",
    "Path(config[\"simulation_run_path\"]).mkdir(parents=True, exist_ok=True)\n",
    "pprint.pprint(dict(config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create GT (ground truth) scenario\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Ground Truth OD + fixed routes\n",
    "print(f\"Reading: {config['file_gt_od']}\")\n",
    "gt_od_df = od_xml_to_df(config[\"file_gt_od\"])\n",
    "\n",
    "print(f\"Reading: {config['fixed_routes']}\")\n",
    "routes_df = pd.read_csv(config[\"fixed_routes\"], index_col=0)\n",
    "\n",
    "# if config[\"edge_selection\"] exists\n",
    "if \"edge_selection\" in config:\n",
    "    if not os.path.exists(config[\"edge_selection\"]):\n",
    "        edge_selection = None\n",
    "    else:\n",
    "        print(f\"Reading: {config['edge_selection']}\")\n",
    "        edge_selection = pd.read_csv(config[\"edge_selection\"], header=None)\n",
    "        edge_selection.columns = [\"edge_id\"]\n",
    "        edge_selection = edge_selection[\"edge_id\"].tolist()\n",
    "else:\n",
    "    edge_selection = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulate the GT scenario to obtain the GT traffic statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_gt_run_path =f'{config[\"simulation_run_path\"]}/ground_truth'\n",
    "prefix_output_gt = f'{simulation_gt_run_path}/sim'\n",
    "sim_edge_out_gt = f'{prefix_output_gt}_{config[\"EDGE_OUT_STR\"]}'\n",
    "new_od_xml = f'{simulation_gt_run_path}/od.xml'\n",
    "\n",
    "Path(simulation_gt_run_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "base_od = gt_od_df.copy()\n",
    "gt_od_vals = gt_od_df['count'].astype(float).to_numpy()\n",
    "curr_od = gt_od_vals.copy()\n",
    "base_od['count'] = curr_od\n",
    "base_od = base_od.rename(columns={'fromTaz':'from', 'toTaz':'to'})        \n",
    "create_taz_xml(new_od_xml, base_od, config[\"od_duration_sec\"], base_path)\n",
    "print(base_od)\n",
    "\n",
    "# Run simulation\n",
    "simulate_od(new_od_xml, \n",
    "            prefix_output_gt, \n",
    "            base_path, \n",
    "            config[\"net_xml\"], \n",
    "            config[\"taz2edge_xml\"], \n",
    "            config[\"additional_xml\"],\n",
    "            routes_df,\n",
    "            config[\"sim_end_time\"],\n",
    "            config[\"TRIPS2ODS_OUT_STR\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read and process the GT simulation outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edge_gt, _, _ = parse_loop_data_xml_to_pandas(base_path, sim_edge_out_gt, prefix_output_gt, config[\"SUMO_PATH\"], edge_list=edge_selection)\n",
    "# picking at edges as GT edges\n",
    "num_gt_edges = df_edge_gt.shape[0]\n",
    "print(\"Number of GT edges:\",num_gt_edges)\n",
    "gt_edge_data = df_edge_gt\\\n",
    "    .sort_values(by=['interval_nVehContrib'], ascending=False)\\\n",
    "    .iloc[:num_gt_edges]\n",
    "\n",
    "print(sim_edge_out_gt)\n",
    "print(gt_edge_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization\n",
    "\n",
    "Vanilla Bayesian Optimization (BO)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayesian optimization utils / helpers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_gp_model(train_X,train_Y):\n",
    "    dim = train_X.size(dim=1)\n",
    "\n",
    "    likelihood = GaussianLikelihood(noise_constraint=Interval(1e-8, 1e-3))\n",
    "    covar_module = ScaleKernel(  # Use the same lengthscale prior as in the TuRBO paper\n",
    "        MaternKernel(\n",
    "            nu=2.5, ard_num_dims=dim, lengthscale_constraint=Interval(0.005, 4.0)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    gp_model = SingleTaskGP(\n",
    "        train_X, train_Y,\n",
    "        covar_module=covar_module, likelihood=likelihood,\n",
    "        outcome_transform=Standardize(m=1)\n",
    "    )\n",
    "\n",
    "    gp_mll = ExactMarginalLogLikelihood(gp_model.likelihood, gp_model)\n",
    "\n",
    "    return gp_model, gp_mll\n",
    "\n",
    "def optimize_acqf_and_get_observation(acq_func, bounds, device, dtype, BATCH_SIZE, NUM_RESTARTS, RAW_SAMPLES):\n",
    "    \"\"\"Optimizes the acquisition function, and returns a new candidate.\"\"\"\n",
    "\n",
    "    dim = acq_func.model.train_inputs[0].size(dim=1)\n",
    "\n",
    "    # optimize\n",
    "    candidates, _ = optimize_acqf(\n",
    "        acq_function=acq_func,\n",
    "        bounds=torch.tensor([[0.0] * dim, [1.0] * dim], device=device, dtype=dtype),\n",
    "        q=BATCH_SIZE,\n",
    "        num_restarts=NUM_RESTARTS,\n",
    "        raw_samples=RAW_SAMPLES,  # used for intialization heuristic\n",
    "        options={\"batch_limit\": 5, \"maxiter\": 200},\n",
    "    )\n",
    "\n",
    "    # observe new values\n",
    "    new_x = candidates.detach()\n",
    "\n",
    "    return unnormalize(new_x, bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "dtype = torch.double\n",
    "\n",
    "dim_od = gt_od_df.shape[0]\n",
    "print(dim_od)\n",
    "\n",
    "bounds = torch.tensor([\n",
    "    [ 0 for _ in range(dim_od)],\n",
    "    [ 2000 for _ in range(dim_od)]\n",
    "], device=device, dtype=dtype) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and simulate a sample of initial input points (i.e., ODs).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample according to Sobol\n",
    "sobol = SobolEngine(dim_od, scramble=True)\n",
    "x_0 = sobol.draw(config[\"n_init_search\"]).to(dtype=dtype).to(device)\n",
    "# map the normalized into the original parameter space\n",
    "train_X0 = unnormalize(x_0, bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ods_epsilon = []\n",
    "loss_all = []\n",
    "batch_data_i = []\n",
    "\n",
    "# Base OD which we will update their count entries\n",
    "base_od = gt_od_df.copy()\n",
    "gt_od_vals = gt_od_df['count'].astype(float).to_numpy()\n",
    "\n",
    "for i , x in enumerate(train_X0.tolist()):\n",
    "      print(f\"########### OD: {i} ###########\")\n",
    "      print(x)\n",
    "      \n",
    "      simulation_run_path_init =f'{config[\"simulation_run_path\"]}/initial_search'\n",
    "      Path(simulation_run_path_init).mkdir(parents=True, exist_ok=True)\n",
    "      \n",
    "      new_od_xml = f\"{simulation_run_path_init}/init_od_{config['network_name']}_{i}.xml\"\n",
    "      prefix_output_init = f'{simulation_run_path_init}/sobol_{i}'\n",
    "\n",
    "      # Generate OD\n",
    "      #curr_od = gt_od_vals.copy()\n",
    "      curr_od = np.array(x)\n",
    "\n",
    "      print(f'total expected GT demand: {np.sum(curr_od)}')\n",
    "\n",
    "      ###\n",
    "      # create OD xml file \n",
    "      ###\n",
    "      base_od['count'] = curr_od\n",
    "      # round to 1 decimal point\n",
    "      base_od['count'] = [round(elem, 1) for elem in base_od['count']]     \n",
    "      base_od = base_od.rename(columns={'fromTaz':'from', 'toTaz':'to'})        \n",
    "      create_taz_xml(new_od_xml, base_od, config[\"od_duration_sec\"], base_path)\n",
    "      ods_epsilon.append(curr_od)\n",
    "\n",
    "      # simulate initial search\n",
    "      simulate_od(new_od_xml, \n",
    "                  prefix_output_init, \n",
    "                  base_path, \n",
    "                  config[\"net_xml\"], \n",
    "                  config[\"taz2edge_xml\"], \n",
    "                  config[\"additional_xml\"],\n",
    "                  routes_df,\n",
    "                  config[\"sim_end_time\"],\n",
    "                  config[\"TRIPS2ODS_OUT_STR\"])\n",
    "\n",
    "      ## Compute loss\n",
    "      #prefix_output = f'initial_search/sobol_{i}'\n",
    "      sim_edge_out = f'{base_path}/{prefix_output_init}_{config[\"EDGE_OUT_STR\"]}'\n",
    "      print(sim_edge_out)\n",
    "      curr_loop_stats, _, _ = parse_loop_data_xml_to_pandas(base_path, sim_edge_out,prefix_output_init,config[\"SUMO_PATH\"], edge_list=edge_selection)\n",
    "      curr_loss = compute_nrmse_counts_all_edges(gt_edge_data, curr_loop_stats)\n",
    "\n",
    "      loss_all.append(curr_loss)\n",
    "      print(f\"############## loss: {curr_loss} ##############\")\n",
    "\n",
    "      # Parse training data\n",
    "      df_curr = pd.DataFrame(curr_od.reshape(1,dim_od),\n",
    "                        columns = [f\"x_{i+1}\" for i in range(dim_od)])\n",
    "      df_curr['loss'] = curr_loss\n",
    "      batch_data_i.append(df_curr)\n",
    "\n",
    "df_initial_bo = pd.concat(batch_data_i)\n",
    "# Save initial dataset\n",
    "df_initial_bo.to_csv(f\"{simulation_run_path_init}/data_set_ods_0_2000.csv\",index=None)\n",
    "print(f\"save df_initial_bo at {simulation_run_path_init}/data_set_ods_0_2000.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run BO epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = StochasticSampler(sample_shape=torch.Size([config[\"SAMPLE_SHAPE\"]]))\n",
    "df_0 = pd.read_csv(f\"{config['simulation_run_path']}/initial_search/data_set_ods_0_2000.csv\")\n",
    "\n",
    "### Run loop\n",
    "best_value = []\n",
    "\n",
    "# Data frame of current training data\n",
    "df_training = df_0\n",
    "df_training[\"bo_iteration\"] = 0\n",
    "\n",
    "df_edge_stats = pd.DataFrame()\n",
    "\n",
    "#num_epsilon_iter = 2\n",
    "ods_epsilon = []\n",
    "loss_all = []\n",
    "batch_data_i = []\n",
    "\n",
    "# Base OD which we will update their count entries\n",
    "base_od = gt_od_df.copy()\n",
    "gt_od_vals = gt_od_df['count'].astype(float).to_numpy()\n",
    "\n",
    "# TODO for loop for multiple restarts\n",
    "for i in range(config[\"NITER\"]):\n",
    "    # new_od_xml = f'{config[\"simulation_run_path\"]}/od.xml'\n",
    "    #   new_od_xml = f\"{simulation_run_path_init}/init_od_{config['network_name']}_{i}.xml\"\n",
    "    #   prefix_output_init = f'{simulation_run_path_init}/sobol_{i}'\n",
    "\n",
    "    simulation_run_path_BO =f'{config[\"simulation_run_path\"]}/BO'\n",
    "    Path(simulation_run_path_BO).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    ########\n",
    "    # Start BO step\n",
    "    ########\n",
    "\n",
    "    print(f\"########### BO iteration={i+1} ###########\")\n",
    "\n",
    "    # Obtain sampling locations x\n",
    "    train_X = torch.from_numpy(\n",
    "        df_training[[col for col in df_training.columns if \"x\" in col]].values\n",
    "    ).to(device=device, dtype=dtype)\n",
    "\n",
    "    # Normalize\n",
    "    train_X_norm = normalize(train_X,bounds)\n",
    "\n",
    "    # Obtain reponse data\n",
    "    train_Y = -torch.from_numpy(df_training[[\"loss\"]].values) # Take negative\n",
    "\n",
    "    # best value so far\n",
    "    best_y = train_Y.max()\n",
    "    best_value.append(best_y)\n",
    "    print(f\"##### best_value={best_y} #####\")\n",
    "\n",
    "    print(f\"Generating new sampling location(s)....\")\n",
    "    # Declare model with newest data\n",
    "    gp_model, gp_mll = initialize_gp_model(train_X_norm,train_Y)\n",
    "\n",
    "    # Fit model\n",
    "    fit_gpytorch_mll(gp_mll)\n",
    "\n",
    "    # Construct acquistion function\n",
    "    # sampler = StochasticSampler(sample_shape=torch.Size([128]))\n",
    "    qEI = qLogExpectedImprovement(gp_model, best_f=best_y, sampler=sampler)\n",
    "\n",
    "    # Maximize acquisition function to get next observation\n",
    "    x_i = optimize_acqf_and_get_observation(acq_func=qEI,\n",
    "                                            bounds=bounds,\n",
    "                                            device=device,\n",
    "                                            dtype=dtype,\n",
    "                                            BATCH_SIZE=config[\"BATCH_SIZE\"],\n",
    "                                            NUM_RESTARTS=config[\"NUM_RESTARTS\"],\n",
    "                                            RAW_SAMPLES=config[\"RAW_SAMPLES\"])\n",
    "    \n",
    "    # if sum(x_i) == 0: skip remainder of loop\n",
    "    if x_i.sum() == 0:\n",
    "        print(\"All zeros, skipping loop\")\n",
    "        continue\n",
    "\n",
    "    # map the normalized into the original parameter space\n",
    "    #x_i = unnormalize(x_i, bounds)\n",
    "    x_i = x_i.cpu().detach().numpy()\n",
    "\n",
    "    ########\n",
    "    # End BO step\n",
    "    ########\n",
    "\n",
    "\n",
    "    # Sample simulator (inner loop across all sampling locations within a batch)\n",
    "    batch_data_i = []\n",
    "    for j in range(config[\"BATCH_SIZE\"]):\n",
    "        loss_all = []\n",
    "        print(f\"########### Sampling location={j+1} ###########\")\n",
    "\n",
    "        new_od_xml_bo = f\"{simulation_run_path_BO}/bayesOpt_od_{config['network_name']}_{i}_{j}.xml\"\n",
    "        prefix_output_bo = f'{simulation_run_path_BO}/bayesOpt_{i}_{j}'\n",
    "\n",
    "        # Generate OD\n",
    "        #curr_od = gt_od_vals.copy()\n",
    "        curr_od = x_i[j]\n",
    "\n",
    "        print(f'total expected GT demand: {np.sum(curr_od)}')\n",
    "\n",
    "        base_od['count'] = curr_od\n",
    "        # round to 1 decimal point\n",
    "        base_od['count'] = [round(elem, 1) for elem in base_od['count']]\n",
    "        base_od = base_od.rename(columns={'fromTaz':'from', 'toTaz':'to'})\n",
    "        create_taz_xml(new_od_xml_bo, base_od, config[\"od_duration_sec\"], base_path)\n",
    "\n",
    "        # simulate gt od\n",
    "        simulate_od(new_od_xml_bo,\n",
    "                    prefix_output_bo,\n",
    "                    base_path,\n",
    "                    config[\"net_xml\"],\n",
    "                    config[\"taz2edge_xml\"],\n",
    "                    config[\"additional_xml\"],\n",
    "                    routes_df,\n",
    "                    config[\"sim_end_time\"],\n",
    "                    config[\"TRIPS2ODS_OUT_STR\"])\n",
    "\n",
    "        ## Compute loss\n",
    "        sim_edge_out = f'{base_path}/{prefix_output_bo}_{config[\"EDGE_OUT_STR\"]}'\n",
    "        print(sim_edge_out)\n",
    "        curr_loop_stats, _, _ = parse_loop_data_xml_to_pandas(base_path, sim_edge_out,prefix_output_bo,config[\"SUMO_PATH\"], edge_list=edge_selection)\n",
    "\n",
    "        curr_loss = compute_nrmse_counts_all_edges(gt_edge_data, curr_loop_stats)\n",
    "        loss_all.append(curr_loss)\n",
    "        print(f\"############## loss: {curr_loss} ##############\")\n",
    "\n",
    "        # Parse training data\n",
    "        df_j = pd.DataFrame(x_i[j].reshape(1,dim_od),\n",
    "                            columns = [f\"x_{i+1}\" for i in range(dim_od)])\n",
    "        df_j['loss'] = curr_loss\n",
    "        batch_data_i.append(df_j)\n",
    "\n",
    "        curr_loop_stats['bo_iteration'] = i\n",
    "        curr_loop_stats['batch'] = j\n",
    "        df_edge_stats = pd.concat([df_edge_stats, curr_loop_stats])\n",
    "\n",
    "    df_i = pd.concat(batch_data_i)\n",
    "    df_i[\"bo_iteration\"] = i+1\n",
    "\n",
    "    df_training = pd.concat([df_training,df_i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"saving at {config['simulation_run_path']}/BO/data_set_bayes_opt.csv\")\n",
    "df_training.to_csv(f\"{config['simulation_run_path']}/BO/data_set_bayes_opt.csv\",index=None)\n",
    "\n",
    "print(f\"saving at {config['simulation_run_path']}/BO/df_edge_stats.csv\")\n",
    "df_edge_stats.to_csv(f\"{config['simulation_run_path']}/BO/df_edge_stats.csv\",index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read BO outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training = pd.read_csv(f\"{config['simulation_run_path']}/BO/data_set_bayes_opt.csv\")\n",
    "df_edge_stats = pd.read_csv(f\"{config['simulation_run_path']}/BO/df_edge_stats.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convergence plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = df_training.query('bo_iteration>0')\n",
    "x = df_plot['bo_iteration']\n",
    "y = df_plot['loss'].cummin()\n",
    "\n",
    "plt.plot(x, y)\n",
    "#plt.legend(title='Parameter where:')\n",
    "plt.xlabel('BO epoch')\n",
    "plt.ylabel('Best NRMSE')\n",
    "# plt.show()\n",
    "plt.savefig(f\"{config['simulation_run_path']}/bo_nrmse.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_edge_stats.batch.drop_duplicates().shape[0] > 1:\n",
    "    raise('This needs updating once we start using batches')\n",
    "\n",
    "losses = []\n",
    "for o1 in range(config[\"NITER\"]): #num_epsilon_iter):\n",
    "    curr_edge_stats = df_edge_stats[df_edge_stats.bo_iteration == o1]\n",
    "    df1b = gt_edge_data.merge(curr_edge_stats, on=['edge_id'], how='left', suffixes=('_gt', '_bo'))\n",
    "    curr_loss = compute_nrmse_counts_all_edges(gt_edge_data, curr_edge_stats)\n",
    "    losses.append(curr_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scatter plots: fit to traffic data\n",
    "\n",
    "Bar plots: fit to OD data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disable interactive mode\n",
    "plt.ioff()\n",
    "\n",
    "if df_edge_stats.batch.drop_duplicates().shape[0] > 1:\n",
    "    raise('This needs updating once we start using batches')\n",
    "\n",
    "Path(f\"{config['simulation_run_path']}/figs\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "losses = []\n",
    "for o1 in range(config[\"NITER\"]): #num_epsilon_iter):\n",
    "    curr_edge_stats = df_edge_stats[df_edge_stats.bo_iteration == o1]\n",
    "    df1b = gt_edge_data.merge(curr_edge_stats, on=['edge_id'], how='left', suffixes=('_gt', '_bo'))\n",
    "    curr_loss = compute_nrmse_counts_all_edges(gt_edge_data, curr_edge_stats)\n",
    "    losses.append(curr_loss)\n",
    "\n",
    "    # find idx of min loss\n",
    "    idx_min = np.argmin(losses)\n",
    "    o1 = idx_min\n",
    "\n",
    "    curr_edge_stats = df_edge_stats[df_edge_stats.bo_iteration == o1]\n",
    "    df1b = gt_edge_data.merge(curr_edge_stats, on=['edge_id'], how='left', suffixes=('_gt', '_bo'))\n",
    "    curr_loss = compute_nrmse_counts_all_edges(gt_edge_data, curr_edge_stats)\n",
    "\n",
    "    plt.figure()    \n",
    "    # plotting diagonal line that represents a perfect data fit\n",
    "    max_val = np.max([df1b.interval_nVehContrib_gt.max(), df1b.interval_nVehContrib_bo.max()])\n",
    "    vec = np.arange(max_val)\n",
    "    plt.plot(vec, vec, 'r-')\n",
    "    plt.plot(df1b.interval_nVehContrib_gt, df1b.interval_nVehContrib_bo, 'x') \n",
    "    # plt.title(f'BO epochs: {o1}; loss: {curr_loss}')\n",
    "    plt.xlabel('GT edge counts') \n",
    "    plt.ylabel('Simulated edge counts') \n",
    "    plt.savefig(f\"{config['simulation_run_path']}/figs/{o1}_bo_edge_counts.png\")\n",
    "\n",
    "\n",
    "    # plot of fit to GT OD vs ET OD\n",
    "    plt.figure()\n",
    "    # get the OD values with the best loss\n",
    "    curr_od = df_training.query('bo_iteration==@o1').iloc[0][[col for col in df_training.columns if \"x\" in col]].values\n",
    "    # bar graph side by side by x axis\n",
    "    width = 0.35\n",
    "    plt.bar(np.arange(len(curr_od)), curr_od, width, label='BO')\n",
    "    plt.bar(np.arange(len(gt_od_vals)) + width, gt_od_vals, width, label='GT')\n",
    "    plt.legend()\n",
    "    plt.xlabel('OD pair')\n",
    "    plt.ylabel('Demand')\n",
    "    # plt.title(f'BO iteration: {o1}')\n",
    "    plt.savefig(f\"{config['simulation_run_path']}/figs/{o1}_bo_od.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save \"Initial\" iteration and \"Best\" iteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw a joint seaborn plot for initial (o1 = 0) and best (o1 = idx_min) iteration\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "o1 = 0\n",
    "curr_edge_stats = df_edge_stats[df_edge_stats.bo_iteration == o1]\n",
    "df1b = gt_edge_data.merge(curr_edge_stats, on=['edge_id'], how='left', suffixes=('_gt', '_bo'))\n",
    "curr_loss = compute_nrmse_counts_all_edges(gt_edge_data, curr_edge_stats)\n",
    "\n",
    "idx_min = np.argmin(losses)\n",
    "o2 = idx_min\n",
    "curr_edge_stats = df_edge_stats[df_edge_stats.bo_iteration == o2]\n",
    "df2b = gt_edge_data.merge(curr_edge_stats, on=['edge_id'], how='left', suffixes=('_gt', '_bo'))\n",
    "\n",
    "# define another df to draw joint plot // hue = bo_iteration\n",
    "df1b['bo_iteration'] = o1\n",
    "df2b['bo_iteration'] = o2\n",
    "df1b['type'] = 'initial'\n",
    "df2b['type'] = 'best'\n",
    "\n",
    "df_joint = pd.concat([df1b, df2b])\n",
    "\n",
    "# plotting diagonal line that represents a perfect data fit\n",
    "max_val = np.max([df1b.interval_nVehContrib_gt.max(), df1b.interval_nVehContrib_bo.max()])\n",
    "vec = np.arange(max_val)\n",
    "\n",
    "fig, ax = plt.subplots(nrows = 1 , ncols = 1, figsize=(5, 4))\n",
    "# initial\n",
    "sns.scatterplot(data=df1b, x='interval_nVehContrib_gt', y='interval_nVehContrib_bo',ax=ax)\n",
    "# x label\n",
    "ax.set_xlabel('GT edge counts')\n",
    "# y label\n",
    "ax.set_ylabel('Simulated edge counts')\n",
    "ax.plot(vec, vec, 'r-')\n",
    "plt.savefig(f\"{config['simulation_run_path']}/{config['network_name']}_jointplot_initial.png\")\n",
    "\n",
    "fig, ax = plt.subplots(nrows = 1 , ncols = 1, figsize=(5, 4))\n",
    "# best\n",
    "sns.scatterplot(data=df2b, x='interval_nVehContrib_gt', y='interval_nVehContrib_bo',ax=ax)\n",
    "# x label\n",
    "ax.set_xlabel('GT edge counts')\n",
    "# y label\n",
    "ax.set_ylabel('Simulated edge counts')\n",
    "ax.plot(vec, vec, 'r-')\n",
    "plt.savefig(f\"{config['simulation_run_path']}/{config['network_name']}_jointplot_best.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config[\"simulation_run_path\"] - \"bo_vanilla\" + \"gridsearch\"\n",
    "gridsearch_path = config[\"simulation_run_path\"].replace(\"bo_vanilla\", \"gridsearch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file_path = f'{gridsearch_path}/simulation_log.txt'\n",
    "data = pd.read_csv(log_file_path, header=None)\n",
    "len_col = data.shape[1]\n",
    "data.columns = [\"od_index\", \"loss\"] + [f\"od_{i}\" for i in range(len_col-2)]\n",
    "data.iloc[:,2:] = data.iloc[:,2:].map(lambda x: round(x, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw a heatmap\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# data.od_0 : x-axis\n",
    "# data.od_1 : y-axis\n",
    "# data.loss : color\n",
    "data_temp = data.copy()\n",
    "# filter 250-750 and 650-1150\n",
    "# data_temp = data_temp[(data_temp['od_0'] >= 250) & (data_temp['od_0'] <= 750)]\n",
    "# data_temp = data_temp[(data_temp['od_1'] >= 650) & (data_temp['od_1'] <= 1150)]\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "heatmap_data = data_temp.pivot_table(index='od_1', columns='od_0', values='loss')\n",
    "cax = ax.imshow(heatmap_data.values, aspect='auto', cmap='coolwarm', \n",
    "                extent=[heatmap_data.columns.min(), heatmap_data.columns.max(), \n",
    "                        heatmap_data.index.min(), heatmap_data.index.max()],\n",
    "                        origin='lower')\n",
    "fig.colorbar(cax)\n",
    "\n",
    "# scatter df_training.x_1 df_training.x_2\n",
    "df_plot = df_training.query('bo_iteration==0')\n",
    "init_x = df_plot['x_1']\n",
    "init_y = df_plot['x_2']\n",
    "ax.scatter(init_x, init_y, color='green', marker='x', s=10, alpha = 0.3)\n",
    "\n",
    "df_plot = df_training.query('bo_iteration>0')\n",
    "# Initialize an empty list to hold the indices where the loss has improved\n",
    "improved_indices = []\n",
    "\n",
    "# Track the minimum loss observed so far\n",
    "min_loss_so_far = float('inf')\n",
    "\n",
    "# Iterate through each row in the filtered DataFrame\n",
    "for idx, row in df_plot.iterrows():\n",
    "    # If the current loss is lower than the minimum loss observed so far\n",
    "    if row['loss'] < min_loss_so_far:\n",
    "        # Update the minimum loss\n",
    "        min_loss_so_far = row['loss']\n",
    "        # Add the current index to the improved indices list\n",
    "        improved_indices.append(idx)\n",
    "\n",
    "\n",
    "df_improved = df_plot.loc[improved_indices]\n",
    "\n",
    "# Get the x_1, x_2, and loss values from the improved rows\n",
    "x = df_improved['x_1']\n",
    "y = df_improved['x_2']\n",
    "loss = df_improved['loss']\n",
    "iter = df_improved['bo_iteration']\n",
    "\n",
    "ax.plot(x, y, '-o', c='black', alpha = 0.5)\n",
    "# put annotation of iter next to red points\n",
    "for i, txt in enumerate(iter):\n",
    "    ax.annotate(txt, (x.iloc[i], y.iloc[i]))\n",
    "\n",
    "# final bo guess (min loss) x_1, x_2 in blue color\n",
    "idx_min = df_training['loss'].idxmin()\n",
    "df_final = df_training.loc[idx_min]\n",
    "final_x = df_final['x_1']\n",
    "final_y = df_final['x_2']\n",
    "\n",
    "ax.scatter(final_x, final_y, color='red', marker='o', s=100)\n",
    "\n",
    "plt.title('NRMSE heatmap')\n",
    "# plt.show()\n",
    "plt.savefig(f\"{config['simulation_run_path']}/{config['network_name']}_NRMSE_heatmap.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
