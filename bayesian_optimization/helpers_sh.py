import json
import os
import xml.etree.ElementTree as ET
from pathlib import Path

import numpy as np
import pandas as pd
import multiprocessing as mp

# pip3 install lxml

def load_experiment_metadata(config_path: str):

    try:
        config = json.load(open(Path(config_path, "config.json") ))
        # config["NETWORK"] = Path(config["NETWORK"])
        config["SUMO"] = Path(config["SUMO"])
    except FileNotFoundError:
        print("config.json not found in ", config_path)
        return None, None
    
    # input_path can be the network-specific subfolder that has the input files for that network. 
    try:
        sim_setup = json.load(open(Path(config_path, "sim_setup.json") ))
    except FileNotFoundError:
        print("sim_setup.json not found in ", config_path)
        return config, None

    return config, sim_setup

def load_kwargs_config(base_path: str, model_name : str, file_name : str):
    config_path = Path(base_path , 'config')
    sim_setup = json.load(open(Path(config_path, file_name) ))

    kwargs_config = {}

    kwargs_config["network_name"] = sim_setup['network_name']
    kwargs_config["model_name"] = model_name

    kwargs_config["network_path"] = Path("network" , sim_setup['network_name'])
    kwargs_config["taz2edge_xml"] = Path(base_path, kwargs_config["network_path"], 'taz.xml')
    kwargs_config["net_xml"] = Path(base_path, kwargs_config["network_path"], 'net.xml')
    kwargs_config["fixed_routes"] = Path(base_path, kwargs_config["network_path"], 'routes.csv')
    kwargs_config["file_gt_od"] = Path(base_path, kwargs_config["network_path"], 'od.xml')
    kwargs_config["additional_xml"] = Path(base_path, kwargs_config["network_path"], 'additional.xml')
    kwargs_config["edge_selection"] = Path(base_path, kwargs_config["network_path"], 'edge_selection.txt')
    kwargs_config["simulation_run_path"] = f"output/{kwargs_config['network_name']}_{kwargs_config['model_name']}" 

    kwargs_config["EDGE_OUT_STR"] = f'edge_data.xml'
    kwargs_config["TRIPS2ODS_OUT_STR"] = 'trips.xml'
    kwargs_config["SUMO_PATH"] = os.environ['SUMO_HOME']

    kwargs_config["sim_start_time"] = sim_setup['sim_start_time']
    kwargs_config["sim_end_time"] = sim_setup['sim_end_time']
    kwargs_config["sim_stat_freq_sec"] = sim_setup['sim_stat_freq_sec']
    kwargs_config["od_duration_sec"] = sim_setup['od_duration_sec']
    kwargs_config["n_init_search"] = sim_setup['n_init_search']

    kwargs_config["NITER"] = sim_setup["BO_niter"]
    kwargs_config["BATCH_SIZE"] = sim_setup["BO_batch_size"]
    kwargs_config["NUM_RESTARTS"] = sim_setup["BO_num_restarts"]
    kwargs_config["RAW_SAMPLES"] = sim_setup["BO_raw_samples"] 
    kwargs_config["SAMPLE_SHAPE"] = sim_setup["BO_sample_shape"]

    kwargs_config["CPU_COUNTS"] = mp.cpu_count()

    return kwargs_config

def od_xml_to_df(file_path):

    tree = ET.parse(file_path)
    root = tree.getroot()
    gt_od_df =  xml2df_str(root, 'tazRelation')
    
    gt_od_vals = gt_od_df['count'].astype(float)
    print('total GT demand: ',gt_od_vals.sum())

    return gt_od_df

def iter_str(author, row_str):
    author_attr = author.attrib
    for doc in author.iter(row_str):
        doc_dict = author_attr.copy()
        doc_dict.update(doc.attrib)
        doc_dict['data'] = doc.text
        yield doc_dict

def xml2df_str(root, row_str):
    return pd.DataFrame(list(iter_str(root, row_str)))

# only keep ODs that are in initial OD set
def is_in_OD_set(routes_df, orig, dest):
    return ((routes_df.fromTaz==orig) and (routes_df.toTaz==dest))

# update the trips file generated by od2trips to get to and from (ie start and end) edges
# that are consistent with a given route choice set. 
# do not use to_xml to print the trips xml file bc we need to guarantee that trips are printed with sorted depart times, as required by sumo
def update_trip_routes(in_trips_xml, out_trips_xml, rtes_df):

    tree = ET.parse(in_trips_xml)
    root = tree.getroot()
    trips_df =  xml2df_str(root, 'trip')
    #rtes_df = pd.read_csv(fixed_routes_xml, header=0, index_col=0)
    # cast tazes to strings to be consistent w/ trips file
    rtes_df['fromTaz'] = rtes_df['fromTaz'].astype(str)
    rtes_df['toTaz'] = rtes_df['toTaz'].astype(str)    
    
    trips_df = trips_df.drop(columns=['to','from'])

    # only keep ODs that are in initial OD set
    trips_df =  trips_df.merge(rtes_df[['fromTaz','toTaz','start_edge','last_edge']], on=['fromTaz','toTaz'], how='inner')    
    trips_df = trips_df.rename(columns={'start_edge':'from','last_edge':'to'})
    

    trips_df['depart_float'] = [float(elem) for elem in trips_df['depart']]
    trips_df = trips_df.sort_values(by='depart_float')

    # write updated tree
    trips_df.to_xml(out_trips_xml, 
                    attr_cols=['id','depart','from','to','type','fromTaz','toTaz','departLane','departSpeed'], 
                    root_name='routes', row_name='trip', index=False
                    )   

    
    # # rewrite tree using elementTree.write so that trips are printed with sorted depart times, as required by sumo
    # print('Sorting updated trips file by  departure time, as required by sumo')
    # root = tree.getroot()
    # tree = ET.parse(out_trips_xml)
    # # sort the first layer
    # root[:] = sorted(root, key=lambda child: (child.tag,child.get('trip')))
    # xmlstr = ET.tostring(root, encoding="utf-8", method="xml")


def create_taz_xml(file_xml, od_df, od_end_time_seconds, base_dir):
    xml_out = f'{base_dir}/{file_xml}'
    od_df.to_xml(xml_out, 
                attr_cols=['from','to','count'], 
                root_name='interval', row_name='tazRelation', index=False)
    
    # define interval attributes
    tree = ET.parse(xml_out)
    root = tree.getroot()
    root.set('id',"DEFAULT_VEHTYPE")
    root.set('begin',"0")
    root.set('end',str(od_end_time_seconds))
    
    # update root node and write new od
    new_root = ET.Element('data')
    new_root.insert(0, root)
    tree = ET.ElementTree(new_root)
    #tree.setroot(new_root)
    tree.write(xml_out)    
    print('Created ', xml_out)


def create_od_xml(current_od, base_od_df, file_od, od_end_time_seconds, base_dir):
    # create OD xml file 

    print(f'total expected GT demand: {np.sum(current_od)}')
    base_od_df['count'] = current_od
    # round to 1 decimal point
    base_od_df['count'] = [round(elem, 1) for elem in base_od_df['count']]     
    base_od_df = base_od_df.rename(columns={'fromTaz':'from', 'toTaz':'to'})        
    create_taz_xml(file_od, base_od_df, od_end_time_seconds, base_dir)

def simulate_od(od_xml:str,
                prefix_output:str, 
                base_dir:str, 
                net_xml:str, 
                taz2edge_xml:str, 
                additional_xml:str,
                routes_df:pd.DataFrame,
                sim_end_time:str,
                TRIPS2ODS_OUT_STR:str,
                sim_start_time=0, seed=0):
    """Runs SUMO using predefined routes and trips file.

    Args:
        od_xml (str): File  name for OD xml file.
        prefix_output (str): Prefix used to identify all files generated for this simluation run.
        base_dir (str): Full path for where the OD, network and other files are localed.
        net_xml (str): File name of network xml.
        taz2edge_xml (str): Traffic assigment zone (TAZ) file.
        additional_xml (str): Additional files needed to run simulation.
        routes_df (pd.DataFrame): Pandas dataframe that includes subset of routes to consider for simluation.
        in order to expedite SUMO run.
        sim_end_time (str): Simulation end time in minutes.
        TRIPS2ODS_OUT_STR (str): _description_
        sim_start_time (int, optional): Simulation start time in minutes. Defaults to 0.
        seed (int, optional): Random seed used in SUMO. Defaults to 0.
    """

    # the [:-4] is to remove the initial xml suffix
    trip_output_file_od2trips_before = f'{base_dir}/{prefix_output}_{TRIPS2ODS_OUT_STR[:-4]}_beforeRteUpdates.xml'
    trip_output_file_od2trips_after = f'{base_dir}/{prefix_output}_{TRIPS2ODS_OUT_STR}'
    od2trips_cmd = (
        #f"od2trips --no-step-log  --spread.uniform "
        f"od2trips  --spread.uniform "
        #Loads TAZ (districts)
        f"--taz-files {taz2edge_xml} " 
        # Loads O/D-matrix in tazRelation format fromFILE(s)
        f"--tazrelation-files {od_xml} "
        # Writes trip definitions into FILE
        f"-o {trip_output_file_od2trips_before}" 
    )


    # Run SUMO to generate outputs
    sumo_run = (
        # Prefix which is applied to all output files. 
        f"sumo --output-prefix {prefix_output}_ " 
        # Do not check whether routes are connected
        f"--ignore-route-errors=true "
        # Load road network description from FILE
        f"--net-file={net_xml} "
        # Load routes descriptions from FILE(s)
        f"--routes={trip_output_file_od2trips_after} "
        #  -b Defines the begin time in seconds; The simulation starts at this time
        # -e Defines the end time in seconds; The simulation ends at this time
        f"-b {sim_start_time} -e {sim_end_time} "
        # Load further descriptions from FILE(s)
        f"--additional-files {additional_xml} "
        f"--duration-log.statistics "
        f"--xml-validation never "
        # Save single vehicle route info into FILE
        f"--vehroutes routes.vehroutes.xml "
        f"--verbose "
        # Disables output of warnings
        f"--no-warnings "
        # Faster simulation (i.e. less detailed)
        f"--mesosim true "
        f"--seed {seed}"
    
    )

    try:
        print(od2trips_cmd)
        os.system(od2trips_cmd)
    except:
        print("Unable to create trips file in od2trips")

    # update to and from edges of the trips file generated by od2trips to 
    # make it consistent with the given route choice file
    update_trip_routes(trip_output_file_od2trips_before, trip_output_file_od2trips_after, routes_df)

    try:
        print("###### Running SUMO #######")
        print(f'Seed {seed}')
        print(sumo_run)
        os.system(sumo_run)
    except:
        print("Unable to run sumo")


def parse_loop_data_xml_to_pandas(base_dir,sim_edge_file,prefix_output,SUMO_PATH, edge_list = None):
    """Read sumo_edge output file. Produce aggregate edge statistics. 
    """

    output_file =f'{base_dir}/{prefix_output}_loopOutputs.csv'
    ## See output explanation:
    # https://sumo.dlr.de/docs/Simulation/Output/Lane-_or_Edge-based_Traffic_Measures.html#generated_output
    # data2csv = (
    #     f"python {SUMO_PATH}/tools/xml/xml2csv.py "
    #     f"{sim_edge_file} "
    #     f"-o {output_file}"
    #     )
    # os.system(data2csv)
    # df_trips = pd.read_csv(output_file, sep=";", header=0)

    root = ET.parse(sim_edge_file).getroot()

    # Initialize an empty list to collect data
    data = []

    # Iterate over intervals and edges to extract data
    for interval in root.findall('interval'):
        interval_begin = interval.get('begin')
        interval_end = interval.get('end')
        interval_id = interval.get('id')
        
        for edge in interval.findall('edge'):
            edge_data = {
                'interval_begin': float(interval_begin),
                'interval_end': float(interval_end),
                'interval_id': interval_id,
                'edge_id': edge.get('id'),
                'edge_sampledSeconds': float(edge.get('sampledSeconds')),
                'edge_traveltime': float(edge.get('traveltime')),
                'edge_overlapTraveltime': float(edge.get('overlapTraveltime')),
                'edge_density': float(edge.get('density')),
                'edge_laneDensity': float(edge.get('laneDensity')),
                'edge_occupancy': float(edge.get('occupancy')),
                'edge_waitingTime': float(edge.get('waitingTime')),
                'edge_timeLoss': float(edge.get('timeLoss')),
                'edge_speed': float(edge.get('speed')),
                'edge_speedRelative': float(edge.get('speedRelative')),
                'edge_departed': float(edge.get('departed')),
                'edge_arrived': float(edge.get('arrived')),
                'edge_entered': float(edge.get('entered')),
                'edge_left': float(edge.get('left')),
                'edge_laneChangedFrom': float(edge.get('laneChangedFrom')),
                'edge_laneChangedTo': float(edge.get('laneChangedTo'))
            }
            data.append(edge_data)

    # Convert list to DataFrame
    df_trips = pd.DataFrame(data)
    df_trips = df_trips[['interval_begin', 'interval_end', 'interval_id', 'edge_arrived',
        'edge_density', 'edge_departed', 'edge_entered', 'edge_id',
        'edge_laneChangedFrom', 'edge_laneChangedTo', 'edge_laneDensity',
        'edge_left', 'edge_occupancy', 'edge_overlapTraveltime',
        'edge_sampledSeconds', 'edge_speed', 'edge_speedRelative',
        'edge_timeLoss', 'edge_traveltime', 'edge_waitingTime']]

    df_trips.to_csv(output_file, index=False) # is this necessary?

    # edge flow in vehicles per hour
    ## edge speed is given in m/s
    ## edge_density is given in no. of vehicles/km

    df_trips['interval_nVehContrib'] = df_trips['edge_arrived'] + df_trips['edge_left']
    #df_trips['interval_nVehContrib'] = 3.6*df_trips['edge_speed']*df_trips['edge_density']


    #df_trips['EdgeID'] = df_trips['edge_id']

    # edge speed is given in m/s
    # computed only for edges that have departed flow
    df_trips['interval_harmonicMeanSpeed'] = df_trips[df_trips['interval_nVehContrib']>0]['edge_speed']
    
    # exclude warm-up period
    #df_trips = df_trips[df_trips['interval_begin']>warm_up_sec]

    # aggregate the rest of the time intervals
    df_agg = df_trips.groupby(by=['edge_id'], as_index=False).agg(
        {'interval_nVehContrib':"sum", 'interval_harmonicMeanSpeed':"mean"})

    if edge_list is not None:
        print(f'Filtering edges to [{edge_list}]')
        df_agg = df_agg[df_agg['edge_id'].isin(edge_list)]

    return df_agg, df_trips, output_file



def compute_nrmse_counts_all_edges(df_true, df_simulated):
    # Merge simulated output with ground truth
    df1 = df_true\
        .merge(df_simulated, on=['edge_id'],
        suffixes=('_GT', '_sim'), how='left')
    
    df1['interval_nVehContrib_sim'] = df1['interval_nVehContrib_sim'].fillna(0)
        
    df1['diff_square'] = (
        df1['interval_nVehContrib_GT'] - df1['interval_nVehContrib_sim']
        )**2
    
    n = df1.shape[0]
    # print('number of GT edges:',n)
    #print(df_true.shape[0])
    #print(df_simulated.shape[0])
    RMSN = np.sqrt(n*(df1['diff_square'].sum()))/df1['interval_nVehContrib_GT'].sum()

    return RMSN


def run_sumo_generate_route_choice(base_dir, prefix_output, seed):
    # Run SUMO to generate route choice set
    # hard-coded inputs: net file, additional file, trip file, beginning and end times (simulating for 5 hours), vehroutes output file
    sumo_run = (
        # Prefix which is applied to all output files. 
        f"sumo --output-prefix {prefix_output}_ " 
        # Do not check whether routes are connected
        f"--ignore-route-errors=true "
        # Load road network description from FILE
        f"--net-file={base_dir}/SFO.net.xml "
        # Load routes descriptions from FILE(s)
        f"--routes=/Users/osorio/HEC/Research/Group/ExternalCollaborations/SergioRodriguez_amazon/notebooks/calibrate_ods/network/SFO/trips24h_smoothed.rou.xml "
        #  -b Defines the begin time in seconds; The simulation starts at this time
        # -e Defines the end time in seconds; The simulation ends at this time
        f"-b 0 -e 18000 "
        # Load further descriptions from FILE(s)
        f"--additional-files {base_dir}/additional.add.xml "
        f"--duration-log.statistics "
        f"--xml-validation never "
        # Save single vehicle route info into FILE
        f"--vehroutes {base_dir}/5hr_sim_routes.vehroutes.xml "
        f"--verbose "
        # Disables output of warnings
        f"--no-warnings "
        # Faster simulation (i.e. less detailed)
        f"--mesosim true "
        # Faster simulation (i.e. less detailed)
        f"--seed {seed} "
    
    )
        # f"--seed {seed}"

    print("###### Running SUMO #######")
    print(sumo_run)
    os.system(sumo_run)

